{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, copy\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests \n",
    "from stop_words import get_stop_words\n",
    "import warnings \n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup \n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "import argparse\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import re\n",
    "import pprint \n",
    "import argparse\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import xmltojson\n",
    "from pprint import pprint\n",
    "import json \n",
    "p = Path('.')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('en')\n",
    "\n",
    "def cited_by_gscholar(dsoup):\n",
    "    cited_by_link_list=[]\n",
    "    for item in dsoup.find_all('div',{\"class\" : \"gs_ri\"}):\n",
    "        cited_by_link_dict={}\n",
    "        authors=[]\n",
    "        for el in item.extract().find_all('a'):\n",
    "            if 'https' in el.get('href').split(':'):\n",
    "                if len(set(['View as HTML', 'Cached']) & set([str(el.text)])) ==0:\n",
    "                    cited_by_link_dict['article_title']=el.text\n",
    "                    cited_by_link_dict['article_link']=el.get('href')\n",
    "            if '/citations?user' in el.get('href'):\n",
    "                authors.append(el.text)\n",
    "            elhref = el.get('href')\n",
    "            if '/scholar?cites' in elhref.split('='):\n",
    "                cited_by_link_dict['cited_by']=elhref\n",
    "            if 'by' in el.text.split():\n",
    "                print(el.text.split())\n",
    "                try: \n",
    "\n",
    "                    citation_cnt=re.findall(r'\\d+', el.text)[0]\n",
    "                    cited_by_link_dict['citations_count']=citation_cnt\n",
    "                    cited_by_link_list.append(cited_by_link_dict)\n",
    "                except Exception:\n",
    "                    pass\n",
    "        cited_by_link_dict['auhtors']=authors\n",
    "    return cited_by_link_list\n",
    "\n",
    "def json_string_dict_values(json_string):\n",
    "    collect_dict_values= {}\n",
    "    for item in json_string.split('\\n'):\n",
    "        ii= item.split('=')\n",
    "        if 'year' in [i.strip() for i in ii ]:\n",
    "            collect_dict_values['year']=re.sub('\\W+','-', item.split('=')[1])\n",
    "        if 'title' in [i.strip() for i in ii ]:\n",
    "            collect_dict_values['title']=re.sub('\\W+','-', item.split('=')[1])\n",
    "        if 'author' in [i.strip() for i in ii ]:\n",
    "            collect_dict_values['author']=re.sub('\\W+','-', item.split('=')[1])\n",
    "            # print(re.sub('\\W+','-', item.split('=')[1]))\n",
    "        if 'journal' in [i.strip() for i in ii ]:\n",
    "            collect_dict_values['journal']=re.sub('\\W+','-', item.split('=')[1])\n",
    "    return collect_dict_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run\n",
    "\n",
    "cmd = 'python ~/Downloads/bibGraphy.py --filename=/Users/krishnaneupane/Downloads/Primo_BibTeX_Export.bib'\n",
    "data = run(cmd, capture_output=True, shell=True)\n",
    "\n",
    "output = data.stdout\n",
    "output =json.loads(json.dumps(output.decode(\"utf-8\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(os.listdir('/Users/krishnaneupane/Downloads/literature_phd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: /Users/krishnaneupane/Downloads/*bib\n"
     ]
    }
   ],
   "source": [
    "!rm ~/Downloads/*bib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article--2011--Savov-Alexi--Asset-pricing-with-garbage--The-Journal-of-Finance.pdf\n",
      "CITATION KEY:  savov2011Asset\n"
     ]
    }
   ],
   "source": [
    "reference_file='/Users/krishnaneupane/Documents/personal/academic/financialanomalies/references.bib'\n",
    "intro_qmd_file='/Users/krishnaneupane/Documents/personal/academic/financialanomalies/intro.qmd'\n",
    "## manual user input\n",
    "url= f'https://scholar.google.com/scholar?cites=965359800876299847&as_sdt=5,47&sciodt=0,47&hl=en' \n",
    "\n",
    "# user manual inputcd \n",
    "#json_string=output\n",
    "\n",
    "json_string= '''\n",
    "@article{savov2011asset,\n",
    "  title={Asset pricing with garbage},\n",
    "  author={Savov, Alexi},\n",
    "  journal={The Journal of Finance},\n",
    "  volume={66},\n",
    "  number={1},\n",
    "  pages={177--201},\n",
    "  year={2011},\n",
    "  publisher={Wiley Online Library}\n",
    "}\n",
    "'''\n",
    "collect_dict_values= json_string_dict_values(json_string)\n",
    "print(''.join(('article-',collect_dict_values['year'],collect_dict_values['author'],\n",
    "               collect_dict_values['title'], collect_dict_values['journal'][:-1],'.pdf',)))\n",
    "#citation_key= [item.split(',') for item in json_string.split('\\n')][0][0].split('{')[1].lower()\n",
    "citation_key=collect_dict_values['author'].split('-')[1].lower() + collect_dict_values['year'].split('-')[1]+\\\n",
    "  ''.join([i for i in collect_dict_values['title'].split('-') if i.lower() not in stop_words and i !=''][:1])\n",
    "\n",
    "#''.join(collect_dict_values['title'].split('-')[1:2]).lower()\n",
    "\n",
    "# c = {}\n",
    "\n",
    "# for k, v in collect_dict_values.items():\n",
    "#     c[k]=' '.join(v.split('-')).strip()\n",
    "print('CITATION KEY: ', citation_key)\n",
    "# os.getcwd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f'@article{c}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/krishnaneupane/Documents/personal/academic/academic_graphs')\n",
    "\n",
    "with open (reference_file, 'a') as reffile:\n",
    "    ref_file=reffile.write(f'\\n{json_string}')\n",
    "    reffile.close()\n",
    "\n",
    "citation_key =f'{citation_key}' # user manual input\n",
    "\n",
    "with open (intro_qmd_file, 'a') as introQmdFile: ## insert citation key at the end of the main page\n",
    "    ref_file=introQmdFile.write(f'\\n@{citation_key}')\n",
    "    introQmdFile.close()\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"\n",
    "}\n",
    "page_contents=requests.get(url,headers=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cited', 'by', '5168']\n",
      "['Cited', 'by', '1641']\n",
      "['Cited', 'by', '450']\n",
      "['Cited', 'by', '263']\n",
      "['Cited', 'by', '47']\n",
      "['Cited', 'by', '390']\n",
      "['Cited', 'by', '88']\n",
      "['Cited', 'by', '156']\n",
      "['Cited', 'by', '282']\n",
      "['Cited', 'by', '227']\n",
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/krishnaneupane/Documents/personal/academic/academic_graphs')\n",
    "\n",
    "citation_dict={}\n",
    "citation_dict['citation_key']=citation_key\n",
    "citation_dict['google_scholar_link']=url\n",
    "citation_dict['cited_by']=cited_by_gscholar(BeautifulSoup(page_contents.text,'lxml'))\n",
    "df = pd.DataFrame.from_dict(citation_dict)\n",
    "df.to_csv('academic_citation_network.csv', mode='a')\n",
    "\n",
    "!clear\n",
    "!export citation_key=($citation_key)\n",
    "!git add .\n",
    "!git status\n",
    "!git commit -m \"$citation_key\"\n",
    "!git push\n",
    "!clear \n",
    "\n",
    "# docker run --rm --init --ulimit core=0 -p 8070:8070 lfoppiano/grobid:0.8.0\n",
    "citation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/krishnaneupane/Documents/personal/academic/financialanomalies\n",
      "\u001b[H\u001b[2J[main 79772ee] yogo2006consumption\n",
      " 4 files changed, 15 insertions(+), 1 deletion(-)\n",
      "Enumerating objects: 11, done.\n",
      "Counting objects: 100% (11/11), done.\n",
      "Delta compression using up to 16 threads\n",
      "Compressing objects: 100% (6/6), done.\n",
      "Writing objects: 100% (6/6), 14.52 KiB | 4.84 MiB/s, done.\n",
      "Total 6 (delta 5), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/krishpn/financialanomalies.git\n",
      "   5d631ce..79772ee  main -> main\n",
      "[1/4] index.qmd\u001b[39m\u001b[22m\n",
      "[2/4] intro.qmd\u001b[39m\u001b[22m\n",
      "[3/4] summary.qmd\u001b[39m\u001b[22m\n",
      "[4/4] references.qmd\u001b[39m\u001b[22m\n",
      "\n",
      "\u001b[1mpandoc \u001b[22m\n",
      "  to: latex\n",
      "  output-file: index.tex\n",
      "  standalone: true\n",
      "  toc: true\n",
      "  number-sections: true\n",
      "  top-level-division: chapter\n",
      "  pdf-engine: xelatex\n",
      "  variables:\n",
      "    graphics: true\n",
      "    tables: true\n",
      "  default-image-extension: pdf\n",
      "  \n",
      "\u001b[1mmetadata\u001b[22m\n",
      "  crossref:\n",
      "    chapters: true\n",
      "  documentclass: scrreprt\n",
      "  papersize: letter\n",
      "  classoption:\n",
      "    - DIV=11\n",
      "    - numbers=noendperiod\n",
      "  header-includes:\n",
      "    - '\\KOMAoption{captions}{tableheading}'\n",
      "  block-headings: true\n",
      "  bibliography:\n",
      "    - references.bib\n",
      "  linestretch: 1.5\n",
      "  title: Financial Anomalies\n",
      "  author: Krishna Neupane\n",
      "  date: 8/24/2024\n",
      "  \n",
      "[WARNING] Citeproc: citation ackert1997Prior not found\n",
      "[WARNING] Citeproc: citation amihud1986Asset not found\n",
      "[WARNING] Citeproc: citation armstrong2011Information not found\n",
      "[WARNING] Citeproc: citation baker2006Investor not found\n",
      "[WARNING] Citeproc: citation balvers2007Productivity not found\n",
      "[WARNING] Citeproc: citation bauman1988Growth not found\n",
      "[WARNING] Citeproc: citation beneish1997Detecting not found\n",
      "[WARNING] Citeproc: citation beneish2013Earnings not found\n",
      "[WARNING] Citeproc: citation boguth2013Consumption not found\n",
      "[WARNING] Citeproc: citation breeden1989Empirical not found\n",
      "[WARNING] Citeproc: citation brennan2013Informed not found\n",
      "[WARNING] Citeproc: citation campbell2004Bad not found\n",
      "[WARNING] Citeproc: citation chang2013Market not found\n",
      "[WARNING] Citeproc: citation chen2012idiosyncratic not found\n",
      "[WARNING] Citeproc: citation chordia2009Theory not found\n",
      "[WARNING] Citeproc: citation cremers2009Takeovers not found\n",
      "[WARNING] Citeproc: citation da2009Cash not found\n",
      "[WARNING] Citeproc: citation dazhi2011dsrr not found\n",
      "[WARNING] Citeproc: citation douglas1967Risk not found\n",
      "[WARNING] Citeproc: citation gokcen2009Information not found\n",
      "[WARNING] Citeproc: citation gopalan2012Asset not found\n",
      "[WARNING] Citeproc: citation gu2005Innovation not found\n",
      "[WARNING] Citeproc: citation gu2011Overpriced not found\n",
      "[WARNING] Citeproc: citation head2009stock not found\n",
      "[WARNING] Citeproc: citation hess2010Projected not found\n",
      "[WARNING] Citeproc: citation huangalanguoming2009tcso not found\n",
      "[WARNING] Citeproc: citation korniotis2009Geography not found\n",
      "[WARNING] Citeproc: citation lettau2001Resurrecting not found\n",
      "[WARNING] Citeproc: citation li2010Real not found\n",
      "[WARNING] Citeproc: citation ortiz2014Real not found\n",
      "[WARNING] Citeproc: citation papanastasopoulosgeorgios2010tior not found\n",
      "[WARNING] Citeproc: citation shu2007Trader not found\n",
      "[WARNING] Citeproc: citation teo2004Style not found\n",
      "\u001b[1mrunning xelatex - 1\u001b[22m\n",
      "  This is XeTeX, Version 3.141592653-2.6-0.999995 (TeX Live 2023) (preloaded format=xelatex)\n",
      "   restricted \\write18 enabled.\n",
      "  entering extended mode\n",
      "  \n",
      "\u001b[1mrunning xelatex - 2\u001b[22m\n",
      "  This is XeTeX, Version 3.141592653-2.6-0.999995 (TeX Live 2023) (preloaded format=xelatex)\n",
      "   restricted \\write18 enabled.\n",
      "  entering extended mode\n",
      "  \n",
      "\n",
      "Output created: Financial-Anomalies.pdf\n",
      "\n",
      "\u001b[32mWatching files for changes\u001b[39m\n",
      "\u001b[32mBrowse at \u001b[39m\u001b[4m\u001b[32mhttp://localhost:7096/web/viewer.html\u001b[39m\u001b[24m\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/krishnaneupane/Documents/personal/academic/financialanomalies\")\n",
    "print(os.getcwd())\n",
    "!sh commitRender.sh $citation_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/krishnaneupane//Downloads/testGorbid/ssrn-3604626.grobid.tei.xml', 'r') as f:\n",
    "    my_xml = f.read()\n",
    "dd= json.loads(xmltojson.parse(my_xml))\n",
    "\n",
    "\n",
    "main_pub_root= dd.get('TEI').get('teiHeader').get('fileDesc').get('sourceDesc').get('biblStruct')\n",
    "\n",
    "main_pub_date= main_pub_root.get('monogr').get('imprint').get('date').get(\"#text\")\n",
    "\n",
    "\n",
    "main_pub_title = main_pub_root.get('analytic').get('title').get(\"#text\")\n",
    "\n",
    "\n",
    "for item in main_pub_root.get('analytic').get('author'):\n",
    "    fname= item.get('persName').get('forename')\n",
    "\n",
    "    if  isinstance(fname, list):\n",
    "        flname=[i['#text'] for i in fname]\n",
    "        lname= item['persName'].get('surname')\n",
    "        flname= flname + [lname]\n",
    "        flname= ' '.join(flname)\n",
    "        print(flname,lname,main_pub_title, main_pub_date)\n",
    "    else:\n",
    "        fname= item.get('persName').get('forename').get('#text')\n",
    "        lname= item['persName'].get('surname')\n",
    "        flname= fname +' '+ lname\n",
    "        print(flname, lname,main_pub_title, main_pub_date)\n",
    "\n",
    "for item in dd['TEI']['text']['back']['div']:\n",
    "    if 'listBibl' in list(item.keys()):\n",
    "        for sitem in item['listBibl']['biblStruct']:\n",
    "            journal = sitem.get('monogr').get('title').get('#text')\n",
    "            try: \n",
    "                title= sitem['analytic']['title']['#text']\n",
    "    \n",
    "                for stitle in sitem['analytic']['author']:\n",
    "                    fname= stitle.get('persName').get('forename')\n",
    "                    if  isinstance(fname, list):\n",
    "                        flname=[i['#text'] for i in fname]\n",
    "                        lname= stitle['persName'].get('surname')\n",
    "                        flname= flname + [lname]\n",
    "                        flname= ' '.join(flname)\n",
    "                        year_pub = sitem.get('monogr').get('imprint').get('date').get('#text')\n",
    "                        print(year_pub, title,flname, journal)\n",
    "                    else:\n",
    "                        fname= stitle.get('persName').get('forename').get('#text')\n",
    "                        lname= stitle['persName'].get('surname')\n",
    "                        flname= fname +' '+ lname\n",
    "                        year_pub = sitem.get('monogr').get('imprint').get('date').get('#text')\n",
    "                        print(year_pub, title, flname, journal)\n",
    "            except Exception:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, copy\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests \n",
    "from stop_words import get_stop_words\n",
    "import warnings \n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup \n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "import argparse\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import re\n",
    "import pprint \n",
    "import argparse\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "p = Path('.')\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def cited_by_gscholar(dsoup):\n",
    "    cited_by_link_list=[]\n",
    "    for item in dsoup.find_all('div',{\"class\" : \"gs_ri\"}):\n",
    "        cited_by_link_dict={}\n",
    "        authors=[]\n",
    "        for el in item.extract().find_all('a'):\n",
    "            if 'https' in el.get('href').split(':'):\n",
    "                if len(set(['View as HTML', 'Cached']) & set([str(el.text)])) ==0:\n",
    "                    cited_by_link_dict['article_title']=el.text\n",
    "                    cited_by_link_dict['article_link']=el.get('href')\n",
    "            if '/citations?user' in el.get('href'):\n",
    "                authors.append(el.text)\n",
    "            elhref = el.get('href')\n",
    "            if '/scholar?cites' in elhref.split('='):\n",
    "                cited_by_link_dict['cited_by']=elhref\n",
    "            if 'by' in el.text.split():\n",
    "                #print(el.text.split())\n",
    "                citation_cnt=re.findall(r'\\d+', el.text)[0]\n",
    "                cited_by_link_dict['citations_count']=citation_cnt\n",
    "                cited_by_link_list.append(cited_by_link_dict)\n",
    "        cited_by_link_dict['auhtors']=authors\n",
    "    return cited_by_link_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article--2006--Anderson-Christopher-W-and-Garcia-Feijoo-Luis--Empirical-evidence-on-capital-investment-growth-options-and-security-returns--The-journal-of-finance.pdf\n",
      "CITATION KEY:  anderson2006empirical\n",
      "\u001b[H\u001b[2JOn branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   academic_citation_network.csv\u001b[m\n",
      "\t\u001b[31mmodified:   academic_citation_networks_google_scholar.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "json_string='''@article{anderson2006empirical,\n",
    "  title={Empirical evidence on capital investment, growth options, and security returns},\n",
    "  author={Anderson, Christopher W and Garcia-Feijoo, Luis},\n",
    "  journal={The journal of finance},\n",
    "  volume={61},\n",
    "  number={1},\n",
    "  pages={171--194},\n",
    "  year={2006},\n",
    "  publisher={Wiley Online Library}\n",
    "}'''\n",
    "\n",
    "url= f'https://academic.oup.com/rfs/article-abstract/33/5/2019/5236964?redirectedFrom=PDF' # user manual input\n",
    "\n",
    "collect_dict_values= {}\n",
    "for item in json_string.split('\\n'):\n",
    "    ii= item.split('=')\n",
    "    if 'year' in [i.strip() for i in ii ]:\n",
    "        collect_dict_values['year']=re.sub('\\W+','-', item.split('=')[1])\n",
    "    if 'title' in [i.strip() for i in ii ]:\n",
    "        collect_dict_values['title']=re.sub('\\W+','-', item.split('=')[1])\n",
    "    if 'author' in [i.strip() for i in ii ]:\n",
    "        collect_dict_values['author']=re.sub('\\W+','-', item.split('=')[1])\n",
    "        # print(re.sub('\\W+','-', item.split('=')[1]))\n",
    "    if 'journal' in [i.strip() for i in ii ]:\n",
    "        collect_dict_values['journal']=re.sub('\\W+','-', item.split('=')[1])\n",
    "        \n",
    "print(''.join(('article-',collect_dict_values['year'],collect_dict_values['author'],\n",
    "               collect_dict_values['title'], collect_dict_values['journal'][:-1],'.pdf',)))\n",
    "citation_key= [item.split(',') for item in json_string.split('\\n')][0][0].split('{')[1]\n",
    "\n",
    "print('CITATION KEY: ', citation_key)\n",
    "\n",
    "citation_key =f'{citation_key}' # user manual input\n",
    "\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (HTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'}\n",
    "page_contents=requests.get(url,headers=headers)\n",
    "soup=BeautifulSoup(page_contents.text,'html.parser')\n",
    "#dsoup = copy.deepcopy(soup)\n",
    "\n",
    "# driver = webdriver.Chrome('/usr/local/bin/chromedriver')\n",
    "# driver.get(url)\n",
    "# from bs4 import BeautifulSoup\n",
    "# soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "# soup=BeautifulSoup(citation_dict['cited_by'].text,'html.parser')\n",
    "\n",
    "citation_dict={}\n",
    "citation_dict['citation_key']=citation_key\n",
    "citation_dict['google_scholar_link']=url\n",
    "citation_dict['cited_by']=cited_by_gscholar(soup)\n",
    "df = pd.DataFrame.from_dict([citation_dict])\n",
    "df.to_csv('academic_citation_network.csv', mode='a')\n",
    "\n",
    "# driver.close()\n",
    "\n",
    "!clear\n",
    "!git status\n",
    "!export citation_key=($citation_key)\n",
    "!git add .\n",
    "!git commit -m \"$citation_key\"\n",
    "!git push\n",
    "\n",
    "# docker run --rm --init --ulimit core=0 -p 8070:8070 lfoppiano/grobid:0.8.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('/Users/krishnaneupane/Downloads/testGorbid/ssrn-3604626.grobid.tei.xml')\n",
    "root = tree.getroot()\n",
    "for item in root.keys():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltojson\n",
    "from pprint import pprint\n",
    "import json \n",
    "\n",
    "import xmltojson\n",
    "with open('/Users/krishnaneupane/Downloads/testGorbid/ssrn-3604626.grobid.tei.xml', 'r') as f:\n",
    "    my_xml = f.read()\n",
    "dd= json.loads(xmltojson.parse(my_xml))\n",
    "\n",
    "for item in dd['TEI']['text']['back']['div']:\n",
    "    if 'listBibl' in list(item.keys()):\n",
    "\n",
    "        for sitem in item['listBibl']['biblStruct']:\n",
    "            journal = sitem.get('monogr').get('title').get('#text')\n",
    "            try: \n",
    "                title= sitem['analytic']['title']['#text']\n",
    "                for stitle in sitem['analytic']['author']:\n",
    "                    fname= stitle.get('persName').get('forename')\n",
    "                    if  isinstance(fname, list):\n",
    "                        flname=[i['#text'] for i in fname]\n",
    "                        lname= stitle['persName'].get('surname')\n",
    "                        flname= flname + [lname]\n",
    "                        flname= ' '.join(flname)\n",
    "                        print(title,flname, journal)\n",
    "                    else:\n",
    "                        fname= stitle.get('persName').get('forename').get('#text')\n",
    "                        lname= stitle['persName'].get('surname')\n",
    "                        flname= fname +' '+ lname\n",
    "                        print(title, flname, journal)\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xmltojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
